{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport gc\nimport psutil\nimport torch\nimport pandas as pd\nimport numpy as np\nimport random\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import make_scorer\nfrom sklearn.model_selection import GridSearchCV\nimport sklearn.feature_selection as fs\nfrom sklearn.linear_model import LassoCV,RidgeCV\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn import preprocessing\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom sklearn.model_selection import KFold,StratifiedKFold\nfrom torch.utils.data import Dataset, DataLoader\nimport tokenizers\n\nimport _pickle as pickle\nfrom tempfile import mkdtemp\nfrom shutil import rmtree\n\nimport statistics\n#from torchsummary import summary\nimport transformers\nfrom tqdm.autonotebook import tqdm\nfrom transformers import (AutoModel, AutoTokenizer, \n                          AutoModelForSequenceClassification,get_constant_schedule_with_warmup,get_linear_schedule_with_warmup)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-18T09:57:39.024823Z","iopub.execute_input":"2021-07-18T09:57:39.025268Z","iopub.status.idle":"2021-07-18T09:57:46.656351Z","shell.execute_reply.started":"2021-07-18T09:57:39.025187Z","shell.execute_reply":"2021-07-18T09:57:46.655508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONASSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nclass Config:\n    learning_rate = 3e-5\n    max_len = 256\n    train_batch_size = 8\n    valid_batch_size = 32\n    epochs = 7\n    stderr_epochs = 7\n    roberta_path = \"../input/roberta-base\"\n    last_layer_size = 768\n    seed = 10\n    kfold = 12\n    file_type = '.bin'\n    svm_model_path = '/kaggle/working/model/svr_model.sav'\n    #save_model_path = \"/kaggle/working/model\"\n    #save_stderr_model_path = \"/kaggle/working/model_stderr\"\n    \n    save_model_path = \"../input/robertabase-clrp/model\"\n    #save_stderr_model_path = \"../input/robertabase-clrp/model_stderr\"\n    #svm_model_path = '../input/robertabase-clrp/model/svr_model.sav'","metadata":{"execution":{"iopub.status.busy":"2021-07-18T09:57:46.657892Z","iopub.execute_input":"2021-07-18T09:57:46.658224Z","iopub.status.idle":"2021-07-18T09:57:46.66718Z","shell.execute_reply.started":"2021-07-18T09:57:46.658188Z","shell.execute_reply":"2021-07-18T09:57:46.666308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\ntrain_data = train_data.sample(frac = 1)\ntest_data_1 = train_data[2700:]\ntrain_data = train_data[0:2700]\n\nos.makedirs('/kaggle/working/model',exist_ok = True)\n#test_data_1.to_csv('/kaggle/working/model' + '/test_data_1.csv')\n\n#temp = train_data.loc[train_data.excerpt.map(lambda x:x.split()).map(len)<170,'target'] \n#print(temp)\n#print(train_data.excerpt.map(lambda x:x.split()).map(len))\n#print(train_data.excerpt.map(lambda x:x.split()).map(len).max()) #205\n\ntest_data = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\ntest_data = test_data.assign(target = 0,standard_error = 0)\nsample = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-18T09:57:46.669249Z","iopub.execute_input":"2021-07-18T09:57:46.669876Z","iopub.status.idle":"2021-07-18T09:57:46.783424Z","shell.execute_reply.started":"2021-07-18T09:57:46.669836Z","shell.execute_reply":"2021-07-18T09:57:46.782612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CLRPDataset(Dataset):\n    def __init__(self,df,tokenizer,max_len):\n        self.excerpt = df['excerpt'].to_numpy()\n        self.max_len = max_len\n        self.tokenizer = tokenizer\n        self.target = df['target'].to_numpy()\n        self.deviation = df['standard_error'].to_numpy()\n        self.id = df['id'].tolist()\n\n    def __getitem__(self,idx):\n        encode = self.tokenizer(self.excerpt[idx],\n                                return_tensors = 'pt',\n                                max_length = self.max_len,\n                                padding = 'max_length',\n                                truncation = True)\n        return {'input_id':encode,'target':torch.tensor(self.target[idx],dtype = torch.float),'id':self.id[idx],\n               'std_err':torch.tensor(self.deviation[idx],dtype = torch.float),'indx':idx}\n    \n    def __len__(self):\n        return len(self.excerpt)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T09:57:46.784938Z","iopub.execute_input":"2021-07-18T09:57:46.785387Z","iopub.status.idle":"2021-07-18T09:57:46.796642Z","shell.execute_reply.started":"2021-07-18T09:57:46.785354Z","shell.execute_reply":"2021-07-18T09:57:46.795777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RMSELoss(torch.nn.Module):\n    def __init__(self):\n        super(RMSELoss,self).__init__()\n\n    def forward(self,x,y):\n        criterion = nn.MSELoss()\n        eps = 1e-6\n        loss = torch.sqrt(criterion(x, y) + eps)\n        return loss\n\nclass SimpleRobertaModel(torch.nn.Module):\n    def __init__(self,model_path):\n        super(SimpleRobertaModel, self).__init__()\n        self.model = AutoModel.from_pretrained(model_path)\n        #self.roberta = transformers.RobertaModel.from_pretrained(Config.roberta_path)\n        self.drop_out = nn.Dropout(0.1)\n        self.l0 = nn.Linear(Config.last_layer_size, 1)\n        torch.nn.init.normal_(self.l0.weight, std=0.02)\n    \n    def forward(self, input_ids, attention_mask):\n\n        out = self.model(\n            input_ids = input_ids,\n            attention_mask = attention_mask,\n            output_hidden_states = True\n        )\n        #out = out.hidden_states\n        #sentence_embeddings = torch.mean(out[12], dim=1)\n        #sentence_embeddings = torch.squeeze(sentence_embeddings,dim=1)\n        \n        out = out.last_hidden_state\n        sentence_embeddings = torch.mean(out, dim=1)\n        sentence_embeddings = torch.squeeze(sentence_embeddings,dim=1)\n        drp_out = self.drop_out(sentence_embeddings)\n        score = self.l0(drp_out)\n        return score","metadata":{"execution":{"iopub.status.busy":"2021-07-18T09:57:46.797963Z","iopub.execute_input":"2021-07-18T09:57:46.798577Z","iopub.status.idle":"2021-07-18T09:57:46.808198Z","shell.execute_reply.started":"2021-07-18T09:57:46.798526Z","shell.execute_reply":"2021-07-18T09:57:46.80707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AttentionHead(nn.Module):\n    def __init__(self, in_features, hidden_dim, num_targets):\n        super().__init__()\n        self.in_features = in_features\n        self.middle_features = hidden_dim\n\n        self.W = nn.Linear(in_features, hidden_dim)\n        self.V = nn.Linear(hidden_dim, 1)\n        self.out_features = hidden_dim\n\n    def forward(self, features):\n        att = torch.tanh(self.W(features))\n        #print('att.shape : ',att.shape) #batch,max_len,768\n        score = self.V(att)\n        #print('score.shape : ',score.shape)\n        attention_weights = torch.softmax(score, dim=1)\n\n        context_vector = attention_weights * features\n        context_vector = torch.sum(context_vector, dim=1)\n        return context_vector\n\nclass RobertaModelAttention(torch.nn.Module):\n    def __init__(self,model_path):\n        super(RobertaModelAttention, self).__init__()\n        self.model = AutoModel.from_pretrained(model_path)\n        self.head = AttentionHead(768,768,1)\n        self.l0 = nn.Linear(self.head.out_features, 1)\n        torch.nn.init.normal_(self.l0.weight, std=0.02)\n    \n    def forward(self, input_ids, attention_mask):\n\n        out = self.model(\n            input_ids = input_ids,\n            attention_mask = attention_mask\n        )\n        x = out[0] # and out.last_hidden_state are same\n        #print(x.shape)\n        x = self.head(x)\n        x = self.l0(x)\n        return x\n        #out = out.last_hidden_state\n        #print('out.shape ',out.size())\n        #sentence_embeddings = torch.mean(out, dim=1)\n        #sentence_embeddings = torch.squeeze(sentence_embeddings,dim=1)\n        #print('sentence_embeddings.shape ',sentence_embeddings.size())\n        #drp_out = self.drop_out(sentence_embeddings)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T09:57:46.810722Z","iopub.execute_input":"2021-07-18T09:57:46.811126Z","iopub.status.idle":"2021-07-18T09:57:46.825186Z","shell.execute_reply.started":"2021-07-18T09:57:46.811097Z","shell.execute_reply":"2021-07-18T09:57:46.824273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rmse_score(y_true,y_pred):\n    return np.sqrt(mean_squared_error(y_true,y_pred))\n\ndef draw_chart(pred,target):\n    #print(target)\n    fig, ax = plt.subplots(1,2,figsize=(20,10))\n    sns.scatterplot(x = target,y = np.abs(pred-target),ax = ax[0])\n    sns.histplot(x = target,y = np.abs(pred-target),ax = ax[1]) \n    ax[0].set_title(\"scatter\",font=\"Serif\")\n    ax[1].set_title(\"histogram\",font=\"Serif\")\n    plt.show()\n\ndef save_model(epoch,model_state_dict,optimizer_state_dict,model_path):\n    state = {\n        'epoch': epoch,\n        'model_state_dict': model_state_dict,\n        #'optimizer_state_dict': optimizer_state_dict,\n        }\n    torch.save(state, model_path)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T09:57:46.826649Z","iopub.execute_input":"2021-07-18T09:57:46.827147Z","iopub.status.idle":"2021-07-18T09:57:46.837674Z","shell.execute_reply.started":"2021-07-18T09:57:46.827097Z","shell.execute_reply":"2021-07-18T09:57:46.836338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def finetune_training(data_loader, model, optimizer, scheduler, dl_valid, kfold):\n    \n    target_var = 'target'\n    model_path = Config.save_model_path + '/model_' + str(kfold) + Config.file_type\n    last_best = 10\n    eval_err = 0\n    diff_count = -1\n    decay_threshold = 0.7\n    \n    while diff_count != 0:\n        '''\n        indx,pred = predict_fn(model,dl_valid if diff_count == -1 else dl_test)\n        target = list()\n        for i, x in enumerate(dl_valid if diff_count == -1 else dl_test):\n            target.extend(x['target'].flatten().tolist())\n        diff = np.abs(np.array(pred) - np.array(target))\n        selected_indx = [val[0] for i,val in enumerate(zip(indx,diff)) if val[1] >= decay_threshold]\n        test_indx = set(indx) - set(selected_indx)\n        failed_df = train_data.loc[selected_indx,:]\n        test_df = train_data.loc[test_indx,:]\n        print('shape of failed and test ',failed_df.shape[0],test_df.shape[0])\n        print(failed_df['target'])\n        diff_count = len(selected_indx)\n        if diff_count == 0:\n            break\n        \n        train_indx = list()\n        for i, x in enumerate(data_loader):\n            train_indx.extend(x['indx'])\n        new_train_df = pd.concat((failed_df,train_data.loc[train_indx]), axis=0)\n        new_train_df = new_train_df.sample(frac = 1)\n        tokenizer = AutoTokenizer.from_pretrained(Config.roberta_path)\n        ds_failed = CLRPDataset(new_train_df,tokenizer,Config.max_len)\n        dl_failed = DataLoader(\n            ds_failed, \n            shuffle = True,\n            batch_size = Config.train_batch_size,\n            num_workers = 4,\n            drop_last = False\n                 )\n        ds_test = CLRPDataset(test_df,tokenizer,Config.max_len)\n        dl_test = DataLoader(\n            ds_test,\n            batch_size = Config.valid_batch_size,\n            num_workers = 4,\n            drop_last = False\n                 )\n        '''\n        for epoch in range(Config.epochs):\n            #training on failed data which is part of validation data\n            #try two other strategies 1) train alone dl_failed with epochs and then train with trainset 2) combine both set and\n            # then train with that....better distribution in combination\n            loss_fn = RMSELoss()\n            rmsescore = list()\n            for i, x in enumerate(data_loader): #old train set\n                model.zero_grad()\n                inputs = {key:val.reshape(val.shape[0],-1).to(device) for key,val in x['input_id'].items()}\n                outputs = model(**inputs)\n                target = x[target_var]\n                loss = loss_fn(outputs.squeeze(),target.to(device))\n                loss.backward()\n                optimizer.step()\n                scheduler.step()\n                rmsescore.append(loss.item())\n                if i%20 == 0:\n                    eval_err = eval_fn(dl_valid, model,target_var)\n                    print('step: ',i,\" | evaluation(finetuning) mean rmse: \",eval_err)\n                    print('training mean rmse: ',np.mean(rmsescore))\n                    if eval_err < last_best :\n                        save_model(epoch,model.state_dict(),optimizer.state_dict(),model_path) \n                        last_best = eval_err\n            print('training mean rmse: ',np.mean(rmsescore))\n            eval_err = eval_fn(dl_valid, model,target_var)\n            if eval_err < last_best : # in case the last few examples improved the performance\n                save_model(epoch,model.state_dict(),optimizer.state_dict(),model_path) \n                last_best = eval_err\n            print(f\"best eval_err for epoch {epoch} in finetuning is : {last_best}\")\n\ndef train_fn(data_loader, model, optimizer, scheduler, dl_valid, kfold):\n    \n    model.train()\n    target_var = 'target'\n    model_path = Config.save_model_path + '/model_' + str(kfold) + Config.file_type\n    #tk0 = tqdm(data_loader, total=len(data_loader))\n    last_best = 10\n    eval_err = 0\n    epoch_eval_error = 10\n    breakcounter =  0 # to breakout of epoch loop when not improving\n    rmsescore = list()\n    for epoch in range(Config.epochs):\n        loss_fn = RMSELoss()\n        for i, x in enumerate(data_loader):\n            model.zero_grad()\n            inputs = {key:val.reshape(val.shape[0],-1).to(device) for key,val in x['input_id'].items()}\n            outputs = model(**inputs)\n            target = x[target_var]\n            loss = loss_fn(outputs.squeeze(),target.to(device))\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n            rmsescore.append(loss.item())\n            if i % 10 == 0:\n                eval_err = eval_fn(dl_valid, model,target_var)\n                #print('step: ',i,\" | evaluation mean rmse: \",eval_err)\n                #print('training mean rmse: ',np.mean(rmsescore))\n                if eval_err < last_best :\n                    save_model(epoch,model.state_dict(),optimizer.state_dict(),model_path)\n                    last_best = eval_err\n        eval_err = eval_fn(dl_valid, model,target_var)\n        #print(f\"epoch: {epoch} | final evaluation mean rmse: {eval_err}\")\n        if eval_err < last_best : # in case the last few examples improved the performance\n            save_model(epoch,model.state_dict(),optimizer.state_dict(),model_path)   \n            last_best = eval_err\n        print(f\"best eval_err for epoch {epoch} is : {last_best}\")\n        if (epoch_eval_error == last_best):\n            breakcounter += 1\n            if breakcounter == 2:\n                break\n        else:\n            epoch_eval_error = last_best\n            breakcounter = 0\n    '''checkpoint = torch.load(model_path)\n    model.load_state_dict(checkpoint['model_state_dict']) # fetch best model to finetune\n    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n    #finetune_training(data_loader, model, optimizer, scheduler, dl_valid, kfold) #after all epochs are done\n    model.train()\n    for epoch in range(Config.epochs):\n        for i, x in enumerate(data_loader):\n            model.zero_grad()\n            inputs = {key:val.reshape(val.shape[0],-1).to(device) for key,val in x['input_id'].items()}\n            outputs = model(**inputs)\n            target = x[target_var]\n            loss = loss_fn(outputs.squeeze(),target.to(device))\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n            rmsescore.append(loss.item())\n            if i%20 == 0:\n                print([param for param in list(model.l0.parameters())])\n                eval_err = eval_fn(dl_valid, model,target_var)\n                print('step: ',i,\" | evaluation mean rmse: \",eval_err)\n                #print('training mean rmse: ',np.mean(rmsescore))\n                #if eval_err < last_best :\n                #    save_model(epoch,model.state_dict(),optimizer.state_dict(),model_path)\n                #    last_best = eval_err\n        eval_err = eval_fn(dl_valid, model,target_var)\n        print(f\"epoch: {epoch} | final evaluation mean rmse: {eval_err}\")\n        if eval_err < last_best : # in case the last few examples improved the performance\n            save_model(epoch,model.state_dict(),optimizer.state_dict(),model_path)\n            last_best = eval_err\n        print(f\"best eval_err for epoch {epoch} is : {last_best}\") '''\n    #drawing scatter plot for difference\n    #model = load_prediction_model(f\"{Config.save_model_path}/model_{kfold}.bin\")\n    #ids,pred = predict_fn(model,dl_valid)\n    #target = list()\n    #for i, x in enumerate(dl_valid):\n    #    target.extend(x['target'].flatten().tolist())\n    #draw_chart(np.array(pred),np.array(target))\n    \ndef eval_fn(data_loader, model,target_var):\n    model.eval()\n    #tk0 = tqdm(data_loader, total=len(data_loader))  \n    scores = list()\n    loss_fn = RMSELoss()\n    with torch.no_grad():\n        for i, X in enumerate(data_loader):\n            inputs = {key:val.reshape(val.shape[0],-1).to(device) for key,val in X['input_id'].items()}\n            outputs = model(**inputs)\n            target = X[target_var]\n            loss = loss_fn(outputs.squeeze(),target.to(device))\n            scores.append(loss.item()) #or just loss.item()\n    #model.train() #affectsthe model performance\n    return np.mean(scores)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T09:57:46.840838Z","iopub.execute_input":"2021-07-18T09:57:46.841398Z","iopub.status.idle":"2021-07-18T09:57:46.870085Z","shell.execute_reply.started":"2021-07-18T09:57:46.841361Z","shell.execute_reply":"2021-07-18T09:57:46.869291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_prediction_model(model_path):\n    \n    model = SimpleRobertaModel(Config.roberta_path)\n    model.to(device)    \n    model.load_state_dict(torch.load(model_path)['model_state_dict'])\n    return model\n        \n#returns index,prediction\ndef predict_fn(model,data_loader):\n    \n    model.eval()\n    output =  list()\n    ids = list()\n    with torch.no_grad():\n        for X in data_loader:\n            inputs = {key:val.reshape(val.shape[0],-1).to(device) for key,val in X['input_id'].items()}\n            outputs = model(**inputs)\n            output.extend(outputs.flatten().tolist())\n            ids.extend(X['indx'])\n    #print(output)\n    return ids,output\n\ndef repeat_prediction(model_path,df):\n    \n    tokenizer = AutoTokenizer.from_pretrained(Config.roberta_path)\n    ds_test = CLRPDataset(df,tokenizer,Config.max_len)\n    dl_test = DataLoader(ds_test,\n              batch_size = Config.valid_batch_size,\n              num_workers = 4,\n              drop_last=False\n             )\n    \n    pred_folds = list()\n    for i in range(Config.kfold):#[0,1,2,3,4,5,6,10]:#\n        model = load_prediction_model(f\"{model_path}/model_{i}{Config.file_type}\")\n        ids,pred = predict_fn(model,dl_test)\n        pred_folds.append(pred)\n    \n    return ids,np.array(pred_folds)\n\ndef final_submission_prediction(model_path):\n\n    ids,pred_folds = repeat_prediction(model_path,test_data)\n    \n    #prediction = np.mean(pred_folds,axis = 0)\n    \n    vec_preds = np.transpose(pred_folds)\n    # load the svm model from disk\n    model = pickle.load(open(Config.svm_model_path, 'rb'))\n    prediction = model.predict(vec_preds)\n    \n    sample.id = sample.loc[ids,'id']\n    sample.target = prediction.tolist()\n    print(sample)\n    sample.to_csv('submission.csv')\n    \ndef final_evaluation_test(model_path,df):\n    \n    #df.reset_index(inplace = True)\n    #ids,pred_folds = repeat_prediction(model_path,df)\n    \n    #with open(\"pred_folds.bin\",\"wb\") as f:\n    #    pickle.dump(pred_folds,f)\n    with open(\"../input/pred-folds/pred_folds.bin\",\"rb\") as f:\n        pred_folds = pickle.load(f)\n    vec_preds = np.transpose(pred_folds)\n    ensemble_preds = np.mean(vec_preds,axis = 1)\n    vec_preds = pd.concat((pd.DataFrame(vec_preds),pd.DataFrame(ensemble_preds),df[['target']]), axis = 1,ignore_index = True)\n    print(vec_preds.shape)\n    #fig, ax = plt.subplots(1,1,figsize=(20,10))\n    annotate = [str(i) for i in range(vec_preds.shape[1]-2)] + ['P','T']\n    fig, axs = plt.subplots(ncols = 2, nrows = int(vec_preds.shape[0]/2),figsize = (15,385))#int(vec_preds.shape[0]/2))\n    fig.tight_layout()\n    for i in range(int(vec_preds.shape[0]/2)):\n        axs[i,0].scatter(x = vec_preds.iloc[i*2],y = np.ones(vec_preds.shape[1]))\n        axs[i,1].scatter(x = vec_preds.iloc[i*2+1],y = np.ones(vec_preds.shape[1]))\n        for j, txt in enumerate(annotate):\n            axs[i,0].annotate(txt, (vec_preds.iloc[i*2][j], 1), fontsize='large')\n            axs[i,1].annotate(txt, (vec_preds.iloc[i*2+1][j], 1), fontsize='large')\n    \n    #ensemble_preds = np.mean(pred_folds,axis = 0)\n    #print(rmse_score(df['target'].to_numpy(), ensemble_preds))\n\ndef svm_model(model_path,df):\n    \n    #ids,pred_folds = repeat_prediction(model_path,df)\n    with open(\"../input/pred-folds/pred_folds.bin\",\"rb\") as f:\n        pred_folds = pickle.load(f)\n    vec_preds = np.transpose(pred_folds)\n    end_point = int(1*vec_preds.shape[0]) - 1\n    train_vec_preds = vec_preds[0:end_point,:]\n    \n    score_fn = make_scorer(rmse_score, greater_is_better = False)\n    model = CrossValidation_SVM(train_vec_preds, df.iloc[0:end_point]['target'], score_fn, kfold = 5)\n    #model.fit(train_vec_preds,df['target'][0:end_point].to_numpy()) #default refit is set to true\n    print(model[1].scores_)\n    pickle.dump(model, open(Config.svm_model_path, 'wb'))\n    \n    #vald_vec_preds = vec_preds[end_point:,:]\n    #prediction = model.predict(vald_vec_preds)\n    #print('rmse: ',rmse_score(df[end_point:]['target'].to_numpy(), prediction))\n\ndef CrossValidation_SVM(df_x, df_y, score_fn, kfold = 5):\n    \n    # Set the parameters by cross-validation\n    mod_str = 'svr__'\n    param_grid = [{ mod_str+'kernel': ['rbf'], mod_str+'gamma': [1e-2, 1e-3, 1e-4, 1e-5], mod_str+'C': [1, 10, 100, 1000]},\n                {mod_str+'kernel': ['linear'], mod_str+'C': [1, 10,]},\n                 {mod_str+'kernel': ['poly'], mod_str+'degree': [3,4,5,6,7,8,9], mod_str+'gamma': [1e-2, 1e-3, 1e-4, 1e-5, 1e-6], mod_str+'coef0': [ 1,2,4,5,6,7,8]}]\n    #param_grid = [{mod_str+'kernel': ['rbf'], mod_str+'gamma': [1e-2, 1e-3], mod_str+'C': [1]},\n    #            {mod_str+'kernel': ['linear'], mod_str+'C': [1, 10,]},\n    #             {mod_str+'kernel': ['poly'], mod_str+'degree': [3,4], mod_str+'gamma': [1e-2], mod_str+'coef0': [1]}]\n    \n    cachedir = mkdtemp()\n    pipeline = make_pipeline(\n        preprocessing.StandardScaler(),\n        fs.SelectKBest(fs.mutual_info_regression, k = 10),\n        SVR(),\n        memory = cachedir,\n        verbose = True\n    )\n    #grid = GridSearchCV(SVR(), param_grid = param_grid,scoring = score_fn, cv = kfold)\n    grid = GridSearchCV(pipeline, param_grid = param_grid, scoring = score_fn, cv = kfold, n_jobs = -1)\n    grid.fit(df_x, df_y)\n    print(\"Best parameters set found on development set:\")\n    print(grid.best_estimator_,grid.best_params_,grid.best_score_)\n    rmtree(cachedir)\n    return grid.best_estimator_","metadata":{"execution":{"iopub.status.busy":"2021-07-18T09:57:46.871473Z","iopub.execute_input":"2021-07-18T09:57:46.872005Z","iopub.status.idle":"2021-07-18T09:57:46.900666Z","shell.execute_reply.started":"2021-07-18T09:57:46.87197Z","shell.execute_reply":"2021-07-18T09:57:46.899682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model(train_len):\n    \n    #model = RobertaModelAttention(Config.roberta_path)\n    model = SimpleRobertaModel(Config.roberta_path)\n    model.to(device)        \n    param_optimizer = list(model.model.named_parameters())\n    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n    #print([param for name, param in param_optimizer if '11' in name ])\n    optimizer_parameters = [\n        {'params': [param for name, param in param_optimizer if not any(nd in name for nd in no_decay)], 'weight_decay': 0.001 },\n        {'params': [param for name, param in param_optimizer if any(nd in name for nd in no_decay)], 'weight_decay': 0.0 },\n        {'params': model.l0.parameters(), 'lr': 1e-2 },\n        #{'params': [param for name, param in param_optimizer if '11' in name ], 'lr': 3e-5},\n        #{'params': [param for name, param in param_optimizer if '11' not in name ], 'lr': 3e-5},\n    ]\n    #print(optimizer_parameters)\n    #print(summary(model, [(1,256), (1,256)]))\n    optimizer = transformers.AdamW(optimizer_parameters, lr = Config.learning_rate)\n    #os._exit()\n    num_train_steps = int(train_len / Config.train_batch_size * Config.epochs)\n    scheduler = get_linear_schedule_with_warmup(\n        optimizer, \n        num_warmup_steps=0, \n        num_training_steps=num_train_steps\n    )\n    return model, optimizer, scheduler\n\ndef CrossValidation_fn(df):\n    kfold = KFold(n_splits = Config.kfold)\n    for k, (train_idx,valid_idx) in enumerate(kfold.split(df)):\n        train= df.iloc[train_idx]\n        valid = df.iloc[valid_idx]        \n        tokenizer = AutoTokenizer.from_pretrained(Config.roberta_path)\n        ds_train = CLRPDataset(train,tokenizer,Config.max_len)\n        dl_train = DataLoader(ds_train, \n                    shuffle = True,\n                    batch_size = Config.train_batch_size,\n                    num_workers = 4,\n                    drop_last = False\n                    )\n        ds_valid = CLRPDataset(valid,tokenizer,Config.max_len)\n        dl_valid = DataLoader(ds_valid,\n                  batch_size = Config.valid_batch_size,\n                  num_workers = 4,\n                  drop_last = False\n                 ) \n        print('kfold val: ', k)\n        model, optimizer, scheduler = create_model(len(train))\n        train_fn(dl_train, model, optimizer, scheduler, dl_valid, k) # either target or stderr model run!\n        #model, optimizer, scheduler = create_model(len(train))\n        #train_stderr_fn(dl_train, model, optimizer, scheduler, dl_valid, k)\n        ","metadata":{"execution":{"iopub.status.busy":"2021-07-18T09:57:46.903042Z","iopub.execute_input":"2021-07-18T09:57:46.90347Z","iopub.status.idle":"2021-07-18T09:57:46.917798Z","shell.execute_reply.started":"2021-07-18T09:57:46.903436Z","shell.execute_reply":"2021-07-18T09:57:46.917002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run():\n \n    #CrossValidation_fn(train_data)\n    #stderr_target_derivation()\n    \n    test_data_1 = pd.read_csv(Config.save_model_path + '/test_data_1.csv')\n    svm_model(Config.save_model_path,test_data_1)\n\n    #final_evaluation_test(Config.save_model_path,test_data_1)\n    final_submission_prediction(Config.save_model_path)\n    #final_submission_prediction(Config.save_stderr_model_path)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"{device} is used\")\nseed_everything(seed = Config.seed)\nprint(psutil.virtual_memory().percent)\ngc.collect()\nprint(psutil.virtual_memory().percent)\nrun()","metadata":{"execution":{"iopub.status.busy":"2021-07-18T09:57:46.921169Z","iopub.execute_input":"2021-07-18T09:57:46.921488Z","iopub.status.idle":"2021-07-18T10:31:51.601487Z","shell.execute_reply.started":"2021-07-18T09:57:46.921461Z","shell.execute_reply":"2021-07-18T10:31:51.600472Z"},"trusted":true},"execution_count":null,"outputs":[]}]}
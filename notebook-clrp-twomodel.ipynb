{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install textstat\nfrom tqdm.autonotebook import tqdm\nimport shutil\nimport os\nimport gc\nimport psutil\nimport torch\nimport pandas as pd\nimport torch.nn as nn\nimport numpy as np\nimport textstat\nimport re\nimport statistics\nimport matplotlib.pyplot as plt\n\nfrom nltk.tag import pos_tag\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom collections import Counter\nimport string\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.svm import SVR, SVC\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.metrics import roc_curve                # Calculate the ROC curve\nfrom sklearn.metrics import precision_recall_curve   # Calculate the Precision-Recall curve\nfrom sklearn.metrics import f1_score                 # Calculate the F-score\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn import preprocessing\nfrom sklearn.metrics import make_scorer\nfrom sklearn.model_selection import GridSearchCV\nimport sklearn.feature_selection as fs\nfrom sklearn.linear_model import LassoCV,RidgeCV\n\nimport random\nimport torch.nn.functional as F\nfrom sklearn.model_selection import KFold,StratifiedKFold\nfrom torch.utils.data import Dataset, DataLoader\nimport tokenizers\nimport _pickle as pickle\n\nimport transformers\n#from torchsummary import summary\nfrom transformers import (AutoModel, AutoTokenizer,\n                          AutoModelForSequenceClassification,get_constant_schedule_with_warmup,get_linear_schedule_with_warmup)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-01T12:11:38.450521Z","iopub.execute_input":"2021-08-01T12:11:38.451007Z","iopub.status.idle":"2021-08-01T12:11:45.109608Z","shell.execute_reply.started":"2021-08-01T12:11:38.450965Z","shell.execute_reply":"2021-08-01T12:11:45.108518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\ntrain_data = train_data.sample(frac = 1)\ntrain_data['target_binary'] = 0\ntrain_data.loc[train_data['target'] > -1,'target_binary'] = 1\ntest_data_1 = train_data[2700:]\ntest_data_1.to_csv('test_data_1.csv')\ntrain_data = train_data[0:2700]\ntest_data_1 = pd.read_csv(\"../input/clrp-abovebelow-model/test_data_1.csv\",index_col = 0)\n#print(train_data[(train_data['target'] > -2) & (train_data['target'] < 0)].shape)\ndf_middle = train_data[(train_data['target'] >-2) & (train_data['target'] < 0)]\n#df_middle = df_middle.loc[~df_middle['id'].isin(test_data_1.id)]\n#print(train_data.excerpt.map(lambda x:x.split()).map(len).max()) #205\ndf_above = train_data[train_data['target_binary'] == 1 ]\ndf_below = train_data[train_data['target_binary'] == 0 ]\nprint('above, below, middle ',df_above.shape,df_below.shape,df_middle.shape)\n\ntest_data = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\ntest_data = test_data.assign(target = 0, standard_error = 0, target_binary = 0)\nsample = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-01T12:06:50.596207Z","iopub.execute_input":"2021-08-01T12:06:50.596681Z","iopub.status.idle":"2021-08-01T12:06:50.843114Z","shell.execute_reply.started":"2021-08-01T12:06:50.596632Z","shell.execute_reply":"2021-08-01T12:06:50.841543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed = 42):\n    random.seed(seed)\n    os.environ['PYTHONASSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nclass Config:\n    learning_rate = 3e-5\n    max_len = 256\n    train_batch_size = 8\n    valid_batch_size = 32\n    epochs = 8\n    stderr_epochs = 7\n    roberta_path = \"../input/roberta-base\"\n    last_layer_size = 768\n    seed = 10\n    kfold = 5\n    kfold_classifier = 10\n    classifier_threshold = 0.5\n    #save_model1_path = \"/kaggle/working/abovemodel\"\n    #save_model2_path = \"/kaggle/working/belowmodel\"\n    #save_model3_path = \"/kaggle/working/middlemodel\"\n    #save_classifier_model_path = \"/kaggle/working/classifiermodel\"\n    \n    save_model1_path = \"../input/clrp-abovebelow-model/abovemodel\"\n    save_model2_path = \"../input/clrp-abovebelow-model/belowmodel\"\n    save_model3_path = \"../input/clrp-abovebelow-model/middlemodel\"\n    save_classifier_model_path = \"../input/clrp-abovebelow-model/classifiermodel\"","metadata":{"execution":{"iopub.status.busy":"2021-08-01T12:06:50.845951Z","iopub.execute_input":"2021-08-01T12:06:50.846612Z","iopub.status.idle":"2021-08-01T12:06:50.854496Z","shell.execute_reply.started":"2021-08-01T12:06:50.846572Z","shell.execute_reply":"2021-08-01T12:06:50.853425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rmse_score(y_true,y_pred):\n    return np.sqrt(mean_squared_error(y_true,y_pred))\n\ndef create_features(df):\n    stop_words = set(stopwords.words('english'))\n    \n    df['processed_excerpt'] = [[w for w in word_tokenize(re.sub(r'[^\\w\\s]', '', text)) if not w.lower() in stop_words] \n                               for text in df['excerpt']] #removing punctuation and stopwords\n    #print(df.processed_excerpt)\n    df['mean_syllable'] = df.processed_excerpt.map(lambda x : [textstat.syllable_count(word) for word in x]).map(lambda x: np.mean(x)) #[np.mean(list(map(lambda x:textstat.syllable_count(x),ls))) for ls in df['processed_excerpt']]\n    df['char_per_word'] = df.processed_excerpt.map(lambda x : [len(word) for word in x]).map(lambda x: np.mean(x))\n    df['long_word'] = df.processed_excerpt.map(lambda x : [1 for word in x if len(word) >6] ).map(lambda x: np.sum(x))\n    df['LIX'] = df.excerpt.map(lambda x : textstat.lix(x))\n    df['RIX'] = df.excerpt.map(lambda x : textstat.rix(x))\n    \n    df['avg_wordlen'] = df.excerpt.map(lambda x:x.split()).apply(lambda x : [len(i) for i in x]).map(lambda x: np.mean(x))\n    #df['numberofwords'] = df.excerpt.map(lambda x:x.split()).map(len)\n    df['text_len'] = df.excerpt.map(len)\n    df['lexicon_count'] = [ textstat.lexicon_count(text,removepunct = True) for text in df['excerpt']]\n    df['lexicon_count_withpunc'] = [ textstat.lexicon_count(text,removepunct = False) for text in df['excerpt']]\n    df['sent_count'] = [ textstat.sentence_count(text) for text in df['excerpt']]\n    df['flesch_reading_ease'] = [ textstat.flesch_reading_ease(text) for text in df['excerpt']]\n    df['smog_index'] = [textstat.smog_index(text) for text in df['excerpt']]\n    df['flesch_kincaid_grade'] = [textstat.flesch_kincaid_grade(text) for text in df['excerpt']]\n    df['coleman_liau_index'] = [textstat.coleman_liau_index(text) for text in df['excerpt']]\n    df['automated_readability_index'] = [textstat.automated_readability_index(text) for text in df['excerpt']]\n    df['dale_chall_readability_score'] = [textstat.dale_chall_readability_score(text) for text in df['excerpt']]\n    df['difficult_words'] = [textstat.difficult_words(text) for text in df['excerpt']]\n    df['linsear_write_formula'] = [textstat.linsear_write_formula(text) for text in df['excerpt']]\n    df['gunning_fog'] = [textstat.gunning_fog(text) for text in df['excerpt']]\n    df['text_standard'] = [textstat.text_standard(text, float_output = True) for text in df['excerpt']]\n    #df['mean_wordper_sent']\n    \n    for row in df.itertuples():\n        pos_dict = Counter([k if k not in string.punctuation else \"PUNCT\" for k in \n                        [j for i,j in pos_tag(word_tokenize(df.at[row.Index,'excerpt'])) ]])\n        for key in pos_dict.keys():\n            df.at[row.Index,key] = pos_dict[key]\n    #pos_dict = Counter([j for i,j in pos_tag(word_tokenize(sent))]) #kind of punctuations\n    \n    #avsentence lenght\n\ndef CrossValidation_SVM(df):\n    #create_features(df)\n    features = ['proxy_target','avg_wordlen','char_per_word','long_word','mean_syllable','LIX','RIX','text_len','lexicon_count','lexicon_count_withpunc','sent_count',\n                'flesch_reading_ease','smog_index','flesch_kincaid_grade','coleman_liau_index','automated_readability_index',\n                'dale_chall_readability_score','difficult_words','linsear_write_formula','gunning_fog','text_standard',\n                'CC','CD','DT','EX','FW','IN','JJ','JJR','JJS','LS','MD','NN','NNS','NNP','NNPS','PDT','POS','PRP','RB','RBR',\n                'RBS','RP','SYM','TO','UH','VB','VBG','VBD','VBN','VBP','VBZ','WDT','WP','WRB','PUNCT'\n               ]\n    #print(df[features].head(10))\n    score_fn = make_scorer(rmse_score, greater_is_better = False)\n\n    # Set the parameters by cross-validation\n    param_grid = [{'svr__kernel': ['rbf'], 'svr__gamma': [1e-2, 1e-3, 1e-4, 1e-5], 'svr__C': [1, 10, 100, 1000]},\n                {'svr__kernel': ['linear'], 'svr__C': [1, 10,]}]\n    pipeline = make_pipeline(\n        preprocessing.StandardScaler(),\n        fs.SelectPercentile(fs.chi2, percentile = 80),\n        SVC()\n    )\n    grid = GridSearchCV(pipeline, param_grid = param_grid, cv = 5,verbose = 4)\n    grid.fit(df.iloc[:][features], df.iloc[:]['target_binary'])\n    print(\"Best parameters set found on development set:\")\n    print(grid.best_params_)\n    print()\n    print(\"Grid scores on development set:\")\n    means = grid.cv_results_['mean_test_score']\n    stds = grid.cv_results_['std_test_score']\n    for mean, std, params in zip(means, stds, grid.cv_results_['params']):\n        print(\"%0.3f (+/-%0.03f) for %r\"\n              % (mean, std * 2, params))\n\ndef CrossValidation_lasso(df):\n    #create_features(df)\n    features = ['proxy_target','avg_wordlen','char_per_word','long_word','mean_syllable','LIX','RIX','text_len','lexicon_count','lexicon_count_withpunc','sent_count',\n                'flesch_reading_ease','smog_index','flesch_kincaid_grade','coleman_liau_index','automated_readability_index',\n                'dale_chall_readability_score','difficult_words','linsear_write_formula','gunning_fog','text_standard',\n                'CC','CD','DT','EX','FW','IN','JJ','JJR','JJS','LS','MD','NN','NNS','NNP','NNPS','PDT','POS','PRP','RB','RBR',\n                'RBS','RP','SYM','TO','UH','VB','VBG','VBD','VBN','VBP','VBZ','WDT','WP','WRB','PUNCT'\n               ]\n    print(df[features].head(10))\n    score_fn = make_scorer(rmse_score, greater_is_better = False)\n\n    # Set the parameters by cross-validation\n    scaler = preprocessing.StandardScaler()\n    x_train = fs.SelectPercentile(fs.mutual_info_regression, percentile = 10).fit_transform(scaler.fit_transform(df.iloc[:][features]),df.iloc[:]['target'])\n    \n    model = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1,5,10,40,100],scoring=score_fn,cv=5).fit(x_train,df.iloc[:]['target'])\n    print(model.best_score_,model.alpha_)\n    #print(model.cv_values_)\n    #lcv = LassoCV(cv=5, random_state=Config.seed,max_iter=2000)\n    #model = lcv.fit(scaler.fit_transform(df.iloc[:][features]),df.iloc[:]['target'])\n    \n    # Display results\n    '''EPSILON = 1e-4\n    plt.figure()\n    print(model.alpha_)\n    plt.plot(model.alphas_ + EPSILON, np.sqrt(model.mse_path_.mean(axis=-1)), 'k',\n             label='Average across the folds', linewidth=2)\n    plt.axvline(model.alpha_ + EPSILON, linestyle='--', color='k',\n                label='alpha: CV estimate')\n\n    plt.legend()\n    plt.xlabel(r'$\\alpha$')\n    plt.ylabel('Mean square error')\n    plt.axis('tight')\n    plt.show()'''\n","metadata":{"execution":{"iopub.status.busy":"2021-08-01T12:11:59.003514Z","iopub.execute_input":"2021-08-01T12:11:59.00388Z","iopub.status.idle":"2021-08-01T12:11:59.041196Z","shell.execute_reply.started":"2021-08-01T12:11:59.003846Z","shell.execute_reply":"2021-08-01T12:11:59.04019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"class CLRPDataset(Dataset):\n    def __init__(self,df,tokenizer,max_len=128):\n        self.excerpt = df['excerpt'].to_numpy()\n        self.max_len = max_len\n        self.tokenizer = tokenizer\n        self.target = df['target'].to_numpy()\n        self.target_binary = df['target_binary'].to_numpy()\n        self.id = df['id'].tolist()\n        self.indx = df.index\n\n    def __getitem__(self,idx):\n        encode = self.tokenizer(self.excerpt[idx],\n                                return_tensors='pt',\n                                max_length=self.max_len,\n                                padding='max_length',\n                                truncation=True)\n        return {'input_id':encode,'target':torch.tensor(self.target[idx],dtype = torch.float),'id':self.id[idx],\n               'target_binary':torch.tensor(self.target_binary[idx],dtype = torch.float),'indx':self.indx[idx]}\n    \n    def __len__(self):\n        return len(self.excerpt)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T12:06:50.895012Z","iopub.execute_input":"2021-08-01T12:06:50.895698Z","iopub.status.idle":"2021-08-01T12:06:50.913881Z","shell.execute_reply.started":"2021-08-01T12:06:50.89565Z","shell.execute_reply":"2021-08-01T12:06:50.912707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RMSELoss(torch.nn.Module):\n    def __init__(self):\n        super(RMSELoss,self).__init__()\n\n    def forward(self,x,y):\n        criterion = nn.MSELoss()\n        eps = 1e-6\n        loss = torch.sqrt(criterion(x, y) + eps)\n        return loss\n\nclass SimpleRobertaModel(torch.nn.Module):\n    def __init__(self,model_path):\n        super(SimpleRobertaModel, self).__init__()\n        self.model = AutoModel.from_pretrained(model_path)\n        #self.roberta = transformers.RobertaModel.from_pretrained(Config.roberta_path)\n        self.drop_out = nn.Dropout(0.1)\n        self.l0 = nn.Linear(Config.last_layer_size, 1)\n        torch.nn.init.normal_(self.l0.weight, std=0.02)\n    \n    def forward(self, input_ids, attention_mask):\n\n        out = self.model(\n            input_ids = input_ids,\n            attention_mask = attention_mask\n        )\n        #out = out[-1]\n        out = out.last_hidden_state\n        sentence_embeddings = torch.mean(out, dim=1)\n        sentence_embeddings = torch.squeeze(sentence_embeddings,dim=1)\n        drp_out = self.drop_out(sentence_embeddings)\n        score = self.l0(drp_out)\n        return score","metadata":{"execution":{"iopub.status.busy":"2021-08-01T12:06:50.915368Z","iopub.execute_input":"2021-08-01T12:06:50.915818Z","iopub.status.idle":"2021-08-01T12:06:50.933744Z","shell.execute_reply.started":"2021-08-01T12:06:50.915773Z","shell.execute_reply":"2021-08-01T12:06:50.932746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_classifier(data_loader, model, optimizer, scheduler=None, dl_valid=None, kfold = 0):\n    \n    target_var = 'target_binary'\n    model.train()\n    tk0 = data_loader\n    #tk0 = tqdm(data_loader, total=len(data_loader))\n    last_best = 0\n    eval_err = 0\n    epoch_eval_error = 0\n    breakcounter =  0 # to breakout of epoch loop when not improving\n    \n    for epoch in range(Config.epochs):\n        for i, x in enumerate(tk0):\n            model.zero_grad()\n            inputs = {key:val.reshape(val.shape[0],-1).to(device) for key,val in x['input_id'].items()}\n            outputs = torch.sigmoid(model(**inputs))\n            #print(outputs.shape,x[target_var].shape)\n            loss = F.binary_cross_entropy(outputs.squeeze(),x[target_var].to(device))\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n            #rmsescore.append(loss.cpu().detach().numpy())\n            if i%10 == 0:\n                #print(f\"epoch: {epoch} step: {i}\")\n                acc,f1score = eval_classifier(dl_valid, model,target_var)\n                #print('step: ',i,\" | evaluation accuracy, f1score : \",acc,f1score)\n                if acc > last_best :\n                    torch.save(model.state_dict(), Config.save_classifier_model_path+'/model_'+str(kfold)+'.bin') \n                    last_best = acc\n        #print('epoch: ',epoch,\" | training mean rmse: \",train_err)\n        #eval_err = eval_fn(dl_valid, model,target_var)\n        #print(f\"epoch: {epoch} | final evaluation accuracy: {acc}\")\n        #if eval_err < last_best : # in case the last few examples improved the performance\n        #    torch.save(model.state_dict(), Config.save_model_path+'/model_classifier.bin')\n        #    last_best = eval_err\n        print(f\"best accuracy for epoch {epoch} is : {last_best}\")\n        if (epoch_eval_error == last_best):\n            breakcounter += 1\n            if breakcounter == 2:\n                break\n        else:\n            epoch_eval_error = last_best\n            breakcounter = 0\n        \ndef eval_classifier(data_loader, model,target_var):\n    \n    model.eval()\n    predls = list()\n    target = list()\n    org_target = list()\n    previous_f1score = 0.8\n    with torch.no_grad():\n        for i, X in enumerate(data_loader):\n            inputs = {key:val.reshape(val.shape[0],-1).to(device) for key,val in X['input_id'].items()}\n            outputs = torch.sigmoid(model(**inputs))\n            target.extend(X[target_var].cpu().detach().numpy())\n            #predls.extend(torch.round(outputs.squeeze()).cpu().detach().numpy())\n            predls.extend(outputs.squeeze().cpu().detach().numpy())\n            org_target.extend(X['target'].cpu().detach().numpy())\n    #fpr, tpr, thresholds = roc_curve(target, predls)\n    # Create the Precision-Recall curve\n    precision, recall, thresholds = precision_recall_curve(target, predls)\n    # Calculate the f-score\n    #fscore = (2 * precision * recall) / (precision + recall)\n    # Find the optimal threshold\n    #index = np.argmax(fscore)\n    #fscoreOpt = round(fscore[index], ndigits = 4)\n    thresholdOpt = Config.classifier_threshold #0.5\n    #thresholdOpt = round(thresholds[index], ndigits = 4)\n    prediction = [1 if x >= thresholdOpt else 0 for x in predls]\n    report_dict = classification_report(target, prediction,output_dict = True, zero_division = 0)\n    #print(report_dict['accuracy'])\n    return report_dict['accuracy'],report_dict['0.0']['f1-score']\n    '''\n    print((report_dict['0.0']['f1-score'] + fscoreOpt)/2)\n    if (report_dict['0.0']['f1-score'] + fscoreOpt)/2 > previous_f1score: \n        print('Best Threshold: {}'.format(thresholdOpt))\n        print(classification_report(target, prediction, zero_division=0))\n        previous_f1score = (int(report_dict['0.0']['f1-score']) + fscoreOpt)/2\n        target_idx = [i for i,x in enumerate(zip(prediction,target)) if x[0]!=x[1]]\n        print([org_target[i] for i in target_idx],[x for i,x in enumerate(zip(prediction,target)) if x[0]!=x[1]])\n    '''\n    model.train()\n    ","metadata":{"execution":{"iopub.status.busy":"2021-08-01T12:06:50.935115Z","iopub.execute_input":"2021-08-01T12:06:50.935423Z","iopub.status.idle":"2021-08-01T12:06:50.953847Z","shell.execute_reply.started":"2021-08-01T12:06:50.935396Z","shell.execute_reply":"2021-08-01T12:06:50.952668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_fn(data_loader, model, optimizer, scheduler, dl_valid, model_type, kfold = None):\n    \n    if model_type == 'above':\n        model_path = Config.save_model1_path\n    elif model_type == 'below':\n        model_path = Config.save_model2_path\n    else: #middle\n        model_path = Config.save_model3_path\n    \n    target_var = 'target'\n    model.train()\n    tk0 = data_loader\n    #tk0 = tqdm(data_loader, total=len(data_loader))\n    last_best = 10\n    eval_err = 0\n    epoch_eval_error = 10\n    breakcounter =  0 # to breakout of epoch loop when not improving\n    for epoch in range(Config.epochs):\n        \n        rmsescore = list()\n        loss_fn = RMSELoss()\n        \n        for i, x in enumerate(tk0):\n            model.zero_grad()\n            inputs = {key:val.reshape(val.shape[0],-1).to(device) for key,val in x['input_id'].items()}\n            outputs = model(**inputs)\n            target = x[target_var]\n            loss = loss_fn(outputs.squeeze(),target.to(device))\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n            #rmsescore.append(loss.cpu().detach().numpy())\n            if i%10 == 0:\n                eval_err = eval_fn(dl_valid, model,target_var)\n                #print('step: ',i,\" | evaluation mean rmse: \",eval_err)\n                if eval_err < last_best :\n                    torch.save(model.state_dict(), model_path+'/model_'+str(kfold)+'.bin')\n                    last_best = eval_err\n        #print('epoch: ',epoch,\" | training mean rmse: \",train_err)\n        eval_err = eval_fn(dl_valid, model,target_var)\n        #print(f\"epoch: {epoch} | final evaluation mean rmse: {eval_err}\")\n        if eval_err < last_best : # in case the last few examples improved the performance\n            torch.save(model.state_dict(), model_path+'/model_'+str(kfold)+'.bin')\n            last_best = eval_err\n        print(f\"best eval_err for epoch {epoch} is : {last_best}\")\n        \n        if (epoch_eval_error == last_best):\n            breakcounter += 1\n            if breakcounter == 2:\n                break\n        else:\n            epoch_eval_error = last_best\n            breakcounter = 0\n        \ndef eval_fn(data_loader, model,target_var):\n\n    model.eval()\n    tk0 = data_loader\n    #tk0 = tqdm(data_loader, total=len(data_loader))  \n    scores=list()\n    loss_fn=RMSELoss()\n    with torch.no_grad():\n        for i, X in enumerate(tk0):\n            inputs = {key:val.reshape(val.shape[0],-1).to(device) for key,val in X['input_id'].items()}\n            outputs = model(**inputs)\n            target = X[target_var]\n            loss = loss_fn(outputs.squeeze(),target.to(device))\n            scores.append(loss.cpu().detach().numpy()) #or just loss.item()\n    #model.train()\n    return np.mean(scores)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T12:06:50.95578Z","iopub.execute_input":"2021-08-01T12:06:50.956253Z","iopub.status.idle":"2021-08-01T12:06:50.976986Z","shell.execute_reply.started":"2021-08-01T12:06:50.956206Z","shell.execute_reply":"2021-08-01T12:06:50.976071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_prediction_model(model_path):\n    \n    model = SimpleRobertaModel(Config.roberta_path)\n    model.to(device)    \n    model.load_state_dict(torch.load(model_path))\n    return model\n    \n'''\ndef final_submission(model_path):\n\n    ids,pred_folds = repeat_prediction(model_path,test_data)\n    print(pred_folds)\n    ensemble_preds=np.mean(pred_folds,axis = 0)\n    sample.id = #ids\n    sample.target = ensemble_preds.tolist()\n    print(sample)\n    sample.to_csv('submission.csv',index=False)\n'''\ndef final_submission():\n\n    ids, preds = final_evaluation(test_data)\n    sample.id = ids\n    sample.target = preds\n    print(sample)\n    sample.to_csv('submission.csv',index = False)\n    \ndef predict_fn(model,data_loader,mod_type = 'regressor'):\n    \n    model.eval()\n    output =  list()\n    ids = list()\n    with torch.no_grad():\n        for X in data_loader:\n            inputs = {key:val.reshape(val.shape[0],-1).to(device) for key,val in X['input_id'].items()}\n            if mod_type == 'classifier':\n                outputs = torch.sigmoid(model(**inputs))\n            else:\n                outputs = model(**inputs)\n            output.extend(outputs.flatten().tolist())\n            ids.extend(X['indx'])\n    #print(output)\n    return ids,output\n\ndef repeat_prediction(model_path,df,kfold = Config.kfold,mod_type = 'regressor'):\n    \n    tokenizer = AutoTokenizer.from_pretrained(Config.roberta_path)\n    ds_test = CLRPDataset(df,tokenizer,Config.max_len)\n    dl_test = DataLoader(ds_test,\n              batch_size = Config.valid_batch_size,\n              num_workers = 4,\n              drop_last=False\n             )\n    \n    pred_folds = list()\n    for i in range(kfold):\n        model = load_prediction_model(f\"{model_path}/model_{i}.bin\")\n        ids,pred = predict_fn(model,dl_test,mod_type)\n        pred_folds.append(pred)\n    \n    return ids,np.array(pred_folds)\n\ndef final_evaluation_test(model_path,df,condition):\n    ids,pred_folds = repeat_prediction(model_path,df)\n    ensemble_preds = np.mean(pred_folds,axis = 0)\n    \n    df1 = pd.concat((pd.DataFrame(ids),pd.DataFrame(ensemble_preds)),axis = 1)\n    df1.columns = ['id','preds']\n    df1.to_csv(condition + '_df1.csv',index =  False)\n    df1 = pd.read_csv(condition + \"_df1.csv\", index_col = False)\n    print(pd.concat((df1.reset_index(drop = True),df.loc[df1.id,['target']].reset_index(drop = True)),axis = 1,ignore_index = False))\n    print('df1 previous ',np.sqrt(mean_squared_error(df.loc[df1.id,'target'].to_numpy(), df1.preds)))\n    if condition == 'above':\n        df2 = df1[df1['preds'] < -0.2]\n    else:\n        df2 = df1[df1['preds'] > -1.7]\n    df_temp = df.loc[df2.id]\n    print('df_temp previous',np.sqrt(mean_squared_error(df_temp['target'].to_numpy(), df2.preds)))\n    middle_ids, middle_pred_folds = repeat_prediction(Config.save_model3_path,df_temp)\n    middle_ensemble_preds = np.mean(middle_pred_folds,axis = 0)\n    #ensemble_preds_final = [middle_ensemble_preds[i] if i in set(middle_ids) else ensemble_preds[i] for i in ids]\n    df_temp['previous_prediction'] = df2.preds.to_numpy()\n    df_temp['prediction'] = middle_ensemble_preds# + df_temp['previous_prediction'].to_numpy())/2 \n    #print(df_temp['prediction'])\n    print('df_temp improved : ',np.sqrt(mean_squared_error(df_temp['target'].to_numpy(), df_temp['prediction'].to_numpy())))\n    print(df_temp[['target','previous_prediction','prediction']],df_temp.shape )\n    #print(df_temp[abs(df_temp['target'] - df_temp['prediction']) > 0.4][['target','previous_prediction','prediction']])\n    df1.loc[df1['id'].isin(df_temp.index), 'preds'] = df_temp['prediction'].to_numpy()\n    #print(np.isnan(df1).any(),np.isfinite(df1).all(),np.isnan(df1),np.isfinite(df1),df1)\n    print(condition+' output: ',np.sqrt(mean_squared_error(df['target'].to_numpy(), df1.preds)))\n    return df1.preds.to_numpy(copy = True)\n\ndef final_classficationeval_test(model_path,df):\n    \n    #ids,pred_folds = repeat_prediction(model_path,df, Config.kfold_classifier,'classifier')\n    #with open(\"pred_folds.bin\",\"wb\") as f:\n    #    pickle.dump(pred_folds,f)\n    with open(\"pred_folds.bin\",\"rb\") as f:\n        pred_folds = pickle.load(f)\n    thres_folds = np.where(pred_folds >= Config.classifier_threshold,1,0)\n    ensemble_preds = np.sum(thres_folds,axis = 0)\n    ensemble_preds = np.where(ensemble_preds >= int(Config.kfold_classifier/2),1,0)\n    print(classification_report(df['target_binary'].to_numpy(), ensemble_preds, zero_division = 0))\n    \n    #annotate = [str(i) for i in range(pred_folds.shape[1]-2)] + ['A','T']\n    #fig, axs = plt.subplots(1,figsize = (30,5))\n    #col = [1 if x[0] == x[1] else 2 for x in zip(df['target_binary'].to_numpy(),ensemble_preds)]\n    #axs.scatter(x = df['target'].to_numpy(), y = np.ones(ensemble_preds.shape[0]),c = col)\n    \n    pred_folds = np.transpose(pred_folds)\n    annotate = [str(i) for i in range(pred_folds.shape[1])] + ['P','T','Tar']\n    pred_folds = pd.concat((pd.DataFrame(pred_folds),pd.DataFrame(ensemble_preds),df[['target_binary','target']].reset_index(drop = True)), axis = 1,ignore_index = True)\n    pred_folds.columns = annotate[:]\n    fig, axs = plt.subplots(ncols = 1, nrows = pred_folds.shape[0],figsize = (15,385))#int(vec_preds.shape[0]/2))\n    fig.tight_layout()\n    for i in range(pred_folds.shape[0]):\n        if pred_folds.iloc[i]['P'] != pred_folds.iloc[i]['T']:\n            axs[i].set_title('Axis '+str(i)+' Target Unmatched: '+str(pred_folds.iloc[i]['Tar']))\n        else:\n            axs[i].set_title('Axis '+str(i)+' Target matched: '+str(pred_folds.iloc[i]['Tar']))\n        axs[i].scatter(x = pred_folds.iloc[i][0:-1],y = np.ones(pred_folds.shape[1]-1))\n        for j, txt in enumerate(annotate[:-1]):\n            axs[i].annotate(txt, (pred_folds.iloc[i][j], 1), fontsize='large')\n    \n    return ensemble_preds\n\ndef final_evaluation(df):\n    prediction = final_classficationeval_test(Config.save_classifier_model_path,df)\n    '''idx_above = np.where(prediction == 1,True,False)\n    idx_below = np.where(prediction == 0,True,False)\n    \n    #idx_above = np.where(df['target_binary'] == 1,True,False)\n    #idx_below = np.where(df['target_binary'] == 0,True,False)\n    #os._exit(1)\n    r1 = final_evaluation_test(Config.save_model1_path,df.loc[idx_above],'above')\n    r2 = final_evaluation_test(Config.save_model2_path,df.loc[idx_below],'below')\n    results = np.concatenate((r1,r2))\n    print(np.sqrt(mean_squared_error(np.concatenate((df.loc[idx_above,'target'].to_numpy(),df.loc[idx_below,'target'].to_numpy())), results)))\n    return np.concatenate((df.loc[idx_above,'id'].to_numpy(),df.loc[idx_below,'id'].to_numpy())), results\n'''","metadata":{"execution":{"iopub.status.busy":"2021-08-01T12:06:50.979269Z","iopub.execute_input":"2021-08-01T12:06:50.979626Z","iopub.status.idle":"2021-08-01T12:06:51.019035Z","shell.execute_reply.started":"2021-08-01T12:06:50.979586Z","shell.execute_reply":"2021-08-01T12:06:51.01795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model(train_len):\n    \n    model=SimpleRobertaModel(Config.roberta_path)\n    model.to(device)\n    param_optimizer = list(model.model.named_parameters())\n    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n    #print(param_optimizer)\n    optimizer_parameters = [\n        {'params': [param for name, param in param_optimizer if not any(nd in name for nd in no_decay)], 'weight_decay': 0.001},\n        {'params': [param for name, param in param_optimizer if any(nd in name for nd in no_decay)], 'weight_decay': 0.0},\n        {'params': model.l0.parameters(), 'lr': 1e-2},\n    ]\n    #print(summary(model, [(1,256), (1,256)]))\n    optimizer = transformers.AdamW(optimizer_parameters, lr = Config.learning_rate)\n    #os._exit()\n    num_train_steps = int(train_len / Config.train_batch_size * Config.epochs)\n    scheduler = get_linear_schedule_with_warmup(\n        optimizer, \n        num_warmup_steps=0, \n        num_training_steps=num_train_steps\n    )\n    return model, optimizer, scheduler\n\ndef CrossValidation_fn(df, k_fold, model_type = 'regressor'):\n    kfold = KFold(n_splits = k_fold)\n    for k, (train_idx,valid_idx) in enumerate(kfold.split(df)):\n        train= df.iloc[train_idx]\n        valid = df.iloc[valid_idx]\n        tokenizer = AutoTokenizer.from_pretrained(Config.roberta_path)\n        ds_train = CLRPDataset(train,tokenizer,Config.max_len)\n        dl_train = DataLoader(ds_train, shuffle = True,\n                  batch_size = Config.train_batch_size,\n                  num_workers = 4,\n                  drop_last=False\n                 )\n        ds_valid = CLRPDataset(valid,tokenizer,Config.max_len)\n        dl_valid = DataLoader(ds_valid,\n                  batch_size = Config.valid_batch_size,\n                  num_workers = 4, shuffle = False,\n                  drop_last=False\n                 )        \n        print('kfold val: ', k)\n        model, optimizer, scheduler = create_model(len(train))\n        if model_type == 'classifier':\n            train_classifier(dl_train, model, optimizer, scheduler, dl_valid, k)\n        else:\n            train_fn(dl_train, model, optimizer, scheduler, dl_valid, model_type, k)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T12:06:51.020818Z","iopub.execute_input":"2021-08-01T12:06:51.021243Z","iopub.status.idle":"2021-08-01T12:06:51.042892Z","shell.execute_reply.started":"2021-08-01T12:06:51.021198Z","shell.execute_reply":"2021-08-01T12:06:51.041647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run():\n    os.makedirs(Config.save_classifier_model_path,exist_ok = True)\n    os.makedirs(Config.save_model1_path,exist_ok = True)\n    os.makedirs(Config.save_model2_path,exist_ok = True)\n    os.makedirs(Config.save_model3_path,exist_ok = True)\n    \n    #shutil.rmtree(\"/kaggle/working/abovemodel\")\n    #shutil.rmtree(\"/kaggle/working/belowmodel\")\n    #src = \"../input/clrp-abovebelow-model/abovemodel\"\n    #src_files = os.listdir(src)\n    #shutil.copytree(src, \"/kaggle/working/abovemodel\")\n    #src = \"../input/clrp-abovebelow-model/belowmodel\"\n    #src_files = os.listdir(src)\n    #shutil.copytree(src, \"/kaggle/working/belowmodel\")\n    \n    #for file_name in src_files:\n    #    full_file_name = os.path.join(src, file_name)\n    #    shutil.copy(full_file_name, \"/kaggle/working\")\n    \n    #CrossValidation_fn(df_above,Config.kfold,'above')\n    #print('--------------------------------------------------')\n    #CrossValidation_fn(df_below,Config.kfold,'below')\n    #print('--------------------------------------------------')\n    #CrossValidation_fn(df_middle,Config.kfold,'middle')\n    #print('--------------------------------------------------')\n    #CrossValidation_fn(train_data,Config.kfold_classifier,'classifier')\n    CrossValidation_SVM(train_data)\n    #final_evaluation(test_data_1)\n    #final_submission()\n    \n    #final_evaluation_test(Config.save_model_path,test_data_1)\n    #final_submission(Config.save_model_path)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"{device} is used\")\nseed_everything(seed = Config.seed)\nprint(psutil.virtual_memory().percent)\ngc.collect()\nprint(psutil.virtual_memory().percent)\nrun()","metadata":{"execution":{"iopub.status.busy":"2021-08-01T12:12:10.264454Z","iopub.execute_input":"2021-08-01T12:12:10.264832Z","iopub.status.idle":"2021-08-01T12:12:10.665009Z","shell.execute_reply.started":"2021-08-01T12:12:10.264801Z","shell.execute_reply":"2021-08-01T12:12:10.662519Z"},"trusted":true},"execution_count":null,"outputs":[]}]}